Bootstrap: docker
FROM pytorch/pytorch:1.12.0-cuda11.3-cudnn8-runtime



%labels
	MANTAINER Rohan Gnanaolivu

%setup
	cp ./src/Singularity_gpu_fix.sh $SINGULARITY_ROOTFS
	# add local url of this repository for testing


%environment
	PATH=$PATH:/usr/local/BiG-DRP
	MODEL_DIR=/usr/local/BiG-DRP
	CANDLE_DATA_DIR=/candle_data_dir

%post
	apt-get update -y
	apt-get install wget -y
	apt-get install build-essential -y
	apt-get install git -y
	apt-get install vim -y
	apt-get install subversion -y

	# install gpu fix and clean up
	cd /
	chmod +x Singularity_gpu_fix.sh
        ./Singularity_gpu_fix.sh
	rm Singularity_gpu_fix.sh

        # these three need to be compiled and linked to the cuda libs.
        # at the moment, what works for me is to build these in a
        # singularity shell in a sandbox with the --nv flag to singularity set.


	# create default internal candle_data_dir, map external candle_data_dir here
	mkdir /candle_data_dir

	#install python modules and model prerequites
	pip install --upgrade pip
	python3 -m pip install --pre dgl==1.0.0+cu113 -f https://data.dgl.ai/wheels/cu113/repo.html
	python3 -m pip install --pre dglgo==0.0.2 -f https://data.dgl.ai/wheels-test/repo.html
	python3 -m pip install git+https://github.com/ECP-CANDLE/candle_lib@develop


	git clone -b develop https://github.com/JDACS4C-IMPROVE/BiG-DRP
	cd BiG-DRP
	python3 -m pip install -r requirements.txt

	chmod a+x *.sh
	chmod a+x *.py
	chmod -R 777 *.py
	